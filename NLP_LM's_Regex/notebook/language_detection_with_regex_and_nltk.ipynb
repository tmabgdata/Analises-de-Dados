{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project focuses on detecting the language of text data using **n-gram models** implemented with the **Natural Language Toolkit (NLTK)**. The project involves data cleaning, preprocessing, model training, and evaluation to accurately identify languages such as English, Portuguese, and Spanish from StackOverflow datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Environment Setup](#Environment-Setup)\n",
    "3. [Data Loading](#Data-Loading)\n",
    "4. [Data Preprocessing](#Data-Preprocessing)\n",
    "    - [Cleaning Text](#Cleaning-Text)\n",
    "    - [Generating Bigrams](#Generating-Bigrams)\n",
    "    - [Padding Text](#Padding-Text)\n",
    "5. [Model Training](#Model-Training)\n",
    "    - [Training MLE Models](#Training-MLE-Models)\n",
    "    - [Training Laplace Models](#Training-Laplace-Models)\n",
    "6. [Model Evaluation](#Model-Evaluation)\n",
    "    - [Calculating Perplexity](#Calculating-Perplexity)\n",
    "    - [Assigning Languages](#Assigning-Languages)\n",
    "7. [Results](#Results)\n",
    "8. [Conclusion](#Conclusion)\n",
    "9. [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language detection is a fundamental task in Natural Language Processing (NLP) with applications ranging from text classification to machine translation. This project leverages **n-gram language models** to classify text into three languages: English, Portuguese, and Spanish. By using NLTK's powerful tools, we can build robust models that understand the contextual nuances of each language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have the following libraries installed. You can install any missing libraries using `pip`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install pandas nltk scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.util import bigrams\n",
    "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
    "from nltk.lm import MLE, Laplace\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three cleaned datasets for English, Portuguese, and Spanish stored in the `NLP_LM's_Regex/data_cleaned/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados em Português:\n",
      "      Id                                             Título  \\\n",
      "0   2402         Como fazer hash de senhas de forma segura?   \n",
      "1   6441  Qual é a diferença entre INNER JOIN e OUTER JOIN?   \n",
      "2    579  Por que não devemos usar funções do tipo mysql_*?   \n",
      "3   2539           As mensagens de erro devem se desculpar?   \n",
      "4  17501  Qual é a diferença de API, biblioteca e Framew...   \n",
      "\n",
      "                                             Questão  \\\n",
      "0  <p>Se eu fizer o <em><a href=\"http://pt.wikipe...   \n",
      "1  <p>Qual é a diferença entre <code>INNER JOIN</...   \n",
      "2  <p>Uma dúvida muito comum é por que devemos pa...   \n",
      "3  <p>É comum encontrar uma mensagem de erro que ...   \n",
      "4  <p>Me parecem termos muito próximos e eventual...   \n",
      "\n",
      "                                         Tags  Pontuação  Visualizações  \\\n",
      "0     <hash><segurança><senhas><criptografia>        350          22367   \n",
      "1                                 <sql><join>        276         176953   \n",
      "2                                <php><mysql>        226           9761   \n",
      "3           <aplicação-web><gui><console><ux>        214           5075   \n",
      "4  <api><framework><terminologia><biblioteca>        193          54191   \n",
      "\n",
      "                                    cleaned_code_tag  \n",
      "0  se eu fizer o hash de senhas antes de armazená...  \n",
      "1  qual é a diferença entre code e code podem me ...  \n",
      "2  uma dúvida muito comum é por que devemos parar...  \n",
      "3  é comum encontrar uma mensagem de erro que diz...  \n",
      "4  me parecem termos muito próximos e eventualmen...  \n",
      "\n",
      "Dados em Espanhol:\n",
      "      Id                                             Título  \\\n",
      "0  18232              ¿Cómo evitar la inyección SQL en PHP?   \n",
      "1    197  ¿Por qué mis programas no pueden hacer cálculo...   \n",
      "2     36  ¿Cuál es la diferencia entre un inner y un out...   \n",
      "3  29177  ¿Por qué es considerado una mala práctica util...   \n",
      "4    142  Validar un email en JavaScript que acepte todo...   \n",
      "\n",
      "                                             Questão  \\\n",
      "0  <p>Las sentencias dinámicas son sentencias SQL...   \n",
      "1  <p>Unas veces los cálculos funcionan correctam...   \n",
      "2  <p>¿Cuál es la diferencia entre un <code>inner...   \n",
      "3  <p>La mayoría de nosotros decimos, (muchas vec...   \n",
      "4  <h3>Pregunta</h3>\\n\\n<p>¿Cómo validar un e-mai...   \n",
      "\n",
      "                                                Tags  Pontuação  \\\n",
      "0        <php><mysql><sql><seguridad><inyección-sql>        169   \n",
      "1   <matemáticas><coma-flotante><lenguaje-agnóstico>        141   \n",
      "2                                 <mysql><sql><join>         97   \n",
      "3  <variables><variables-globales><patrones-de-di...         89   \n",
      "4             <javascript><validación><email><regex>         87   \n",
      "\n",
      "   Visualizações                                   cleaned_code_tag  \n",
      "0          38614  las sentencias dinámicas son sentencias s ql q...  \n",
      "1           3860  unas veces los cálculos funcionan correctament...  \n",
      "2          53627  cuál es la diferencia entre un code y un code ...  \n",
      "3           9987  la mayoría de nosotros decimos muchas veces si...  \n",
      "4          73129  pregunta cómo validar un email que acepte todo...  \n",
      "\n",
      "Dados em Inglês:\n",
      "         Id                                             Título  \\\n",
      "0  11227809  Why is it faster to process a sorted array tha...   \n",
      "1    927358  How do I undo the most recent local commits in...   \n",
      "2   2003505  How do I delete a Git branch locally and remot...   \n",
      "3    292357  What is the difference between 'git pull' and ...   \n",
      "4    477816             What is the correct JSON content type?   \n",
      "\n",
      "                                             Questão  \\\n",
      "0  <p>Here is a piece of C++ code that seems very...   \n",
      "1  <p>I accidentally committed the wrong files to...   \n",
      "2  <p>I want to delete a branch both locally and ...   \n",
      "3  <blockquote>\\n  <p><strong>Moderator Note:</st...   \n",
      "4  <p>I've been messing around with <a href=\"http...   \n",
      "\n",
      "                                                Tags  Pontuação  \\\n",
      "0  <java><c++><performance><optimization><branch-...      23057   \n",
      "1           <git><version-control><git-commit><undo>      19640   \n",
      "2                      <git><git-branch><git-remote>      15249   \n",
      "3                         <git><git-pull><git-fetch>      11008   \n",
      "4                 <json><http-headers><content-type>       9701   \n",
      "\n",
      "   Visualizações                                   cleaned_code_tag  \n",
      "0        1358574  here is a piece of c code that seems very pecu...  \n",
      "1        7906137  i accidentally committed the wrong files to gi...  \n",
      "2        6940906  i want to delete a branch both locally and rem...  \n",
      "3        2543052  moderator note given that this question has al...  \n",
      "4        2478940  ive been messing around with j so n for some t...  \n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "caminho_portugues = \"../data_cleaned/stackoverflow_portuguese_clean.csv\"\n",
    "caminho_espanhol = \"../data_cleaned/stackoverflow_spanish_clean.csv\"\n",
    "caminho_ingles = \"../data_cleaned/stackoverflow_english_clean.csv\"\n",
    "\n",
    "# Load datasets\n",
    "dados_portugues = pd.read_csv(caminho_portugues)\n",
    "dados_espanhol = pd.read_csv(caminho_espanhol)\n",
    "dados_ingles = pd.read_csv(caminho_ingles)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Dados em Português:\")\n",
    "print(dados_portugues.head())\n",
    "\n",
    "print(\"\\nDados em Espanhol:\")\n",
    "print(dados_espanhol.head())\n",
    "\n",
    "print(\"\\nDados em Inglês:\")\n",
    "print(dados_ingles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the data has been pre-cleaned using regex functions to remove HTML tags, code snippets, punctuation, digits, extra spaces, and newlines, we will perform additional preprocessing steps to prepare the data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                500 non-null    int64 \n",
      " 1   Título            500 non-null    object\n",
      " 2   Questão           500 non-null    object\n",
      " 3   Tags              500 non-null    object\n",
      " 4   Pontuação         500 non-null    int64 \n",
      " 5   Visualizações     500 non-null    int64 \n",
      " 6   cleaned_code_tag  500 non-null    object\n",
      " 7   idioma            500 non-null    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 31.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                500 non-null    int64 \n",
      " 1   Título            500 non-null    object\n",
      " 2   Questão           500 non-null    object\n",
      " 3   Tags              500 non-null    object\n",
      " 4   Pontuação         500 non-null    int64 \n",
      " 5   Visualizações     500 non-null    int64 \n",
      " 6   cleaned_code_tag  500 non-null    object\n",
      " 7   idioma            500 non-null    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 31.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                500 non-null    int64 \n",
      " 1   Título            500 non-null    object\n",
      " 2   Questão           500 non-null    object\n",
      " 3   Tags              500 non-null    object\n",
      " 4   Pontuação         500 non-null    int64 \n",
      " 5   Visualizações     500 non-null    int64 \n",
      " 6   cleaned_code_tag  500 non-null    object\n",
      " 7   idioma            500 non-null    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Adding language identification\n",
    "dados_portugues[\"idioma\"] = \"portugues\"\n",
    "dados_espanhol[\"idioma\"] = \"espanhol\"\n",
    "dados_ingles[\"idioma\"] = \"ingles\"\n",
    "\n",
    "# Verify the datasets\n",
    "print(dados_portugues.info())\n",
    "print(dados_espanhol.info())\n",
    "print(dados_ingles.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split each language dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting datasets into training and testing\n",
    "port_treino, port_teste = train_test_split(dados_portugues['cleaned_code_tag'], test_size=0.2, random_state=123)\n",
    "esp_treino, esp_teste = train_test_split(dados_espanhol['cleaned_code_tag'], test_size=0.2, random_state=123)\n",
    "ing_treino, ing_teste = train_test_split(dados_ingles['cleaned_code_tag'], test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Bigrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the text and generating bigrams helps the model understand the context within the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sou', 'iniciante', 'em', 'p', 'hp', 'e', 'gostaria', 'de', 'saber', 'se', 'p', 'do', 'ph', 'p', 'data', 'objects', 'é', 'a', 'maneira', 'mais', 'segura', 'de', 'se', 'conectar', 'a', 'um', 'banco', 'de', 'dados', 'preciso', 'também', 'de', 'um', 'exemplo', 'de', 'como', 'fazer', 'esta', 'conexão', 'e', 'inserirselecionar', 'dados', 'por', 'exemplo', 'code', 'estou', 'fazendo', 'um', 'efeito', 'aqui']\n"
     ]
    }
   ],
   "source": [
    "# Function to tokenize and generate bigrams\n",
    "def gerar_bigrams(lista_textos):\n",
    "    todas_questoes = ' '.join(lista_textos)\n",
    "    todas_palavras = WhitespaceTokenizer().tokenize(todas_questoes)\n",
    "    return todas_palavras\n",
    "\n",
    "# Tokenizing words for each language\n",
    "todas_palavras_port = gerar_bigrams(port_treino)\n",
    "todas_palavras_esp = gerar_bigrams(esp_treino)\n",
    "todas_palavras_ing = gerar_bigrams(ing_treino)\n",
    "\n",
    "print(todas_palavras_port[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MLE Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will train Maximum Likelihood Estimation (MLE) models for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train MLE model\n",
    "def treinar_modelo_MLE(lista_textos):\n",
    "    todas_questoes = ' '.join(lista_textos)\n",
    "    todas_palavras = WhitespaceTokenizer().tokenize(todas_questoes)\n",
    "    bigrams_tratados, vocabulario = padded_everygram_pipeline(2, todas_palavras)\n",
    "    modelo = MLE(2)\n",
    "    modelo.fit(bigrams_tratados, vocabulario)\n",
    "    return modelo\n",
    "\n",
    "# Training MLE models\n",
    "modelo_port_MLE = treinar_modelo_MLE(port_treino)\n",
    "modelo_esp_MLE = treinar_modelo_MLE(esp_treino)\n",
    "modelo_ing_MLE = treinar_modelo_MLE(ing_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Laplace Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle unseen bigrams and avoid infinite perplexity, we will train Laplace-smoothed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train Laplace model\n",
    "def treinar_modelo_Laplace(lista_textos):\n",
    "    todas_questoes = ' '.join(lista_textos)\n",
    "    todas_palavras = WhitespaceTokenizer().tokenize(todas_questoes)\n",
    "    bigrams_tratados, vocabulario = padded_everygram_pipeline(2, todas_palavras)\n",
    "    modelo = Laplace(2)\n",
    "    modelo.fit(bigrams_tratados, vocabulario)\n",
    "    return modelo\n",
    "\n",
    "# Training Laplace models\n",
    "modelo_port_Laplace = treinar_modelo_Laplace(port_treino)\n",
    "modelo_esp_Laplace = treinar_modelo_Laplace(esp_treino)\n",
    "modelo_ing_Laplace = treinar_modelo_Laplace(ing_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is a measure of how well a probability model predicts a sample. Lower perplexity indicates a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate perplexity\n",
    "def calcular_perplexidade(modelo, texto):\n",
    "    \"\"\"\n",
    "    Calcula a perplexidade de um texto baseado no modelo fornecido.\n",
    "    - modelo: modelo treinado (MLE ou Laplace)\n",
    "    - texto: string a ser avaliada\n",
    "    \"\"\"\n",
    "    perplexidade = 0\n",
    "    palavras = WhitespaceTokenizer().tokenize(texto)\n",
    "    palavras_fakechar = [list(pad_both_ends(palavra, n=2)) for palavra in palavras]\n",
    "    palavras_bigramns = [list(bigrams(palavra)) for palavra in palavras_fakechar]\n",
    "    \n",
    "    for palavra in palavras_bigramns:\n",
    "        perplexidade += modelo.perplexity(palavra)\n",
    "    \n",
    "    return perplexidade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Languages Based on Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assign a language to each text by comparing the perplexity scores from each language model. The language with the lowest perplexity score is considered the predicted language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign language based on perplexity\n",
    "def atribui_idioma(lista_textos):\n",
    "    \"\"\"\n",
    "    Atribui um idioma a cada texto da lista baseado na menor perplexidade.\n",
    "    - lista_textos: lista de textos (str) a serem classificados\n",
    "    \"\"\"\n",
    "    idiomas = []\n",
    "    for texto in lista_textos:\n",
    "        portugues = calcular_perplexidade(modelo_port_Laplace, texto)\n",
    "        ingles = calcular_perplexidade(modelo_ing_Laplace, texto)\n",
    "        espanhol = calcular_perplexidade(modelo_esp_Laplace, texto)\n",
    "        \n",
    "        if portugues <= ingles and portugues <= espanhol:\n",
    "            idiomas.append(\"portugues\")\n",
    "        elif ingles < portugues and ingles <= espanhol:\n",
    "            idiomas.append(\"ingles\")\n",
    "        else:\n",
    "            idiomas.append(\"espanhol\")\n",
    "    \n",
    "    return idiomas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will classify the test data for each language and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto - Português: 0.99\n",
      "Taxa de acerto - Inglês: 1.00\n",
      "Taxa de acerto - Espanhol: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Classify test data\n",
    "resultados_portugues = atribui_idioma(port_teste)\n",
    "resultados_ingles = atribui_idioma(ing_teste)\n",
    "resultados_espanhol = atribui_idioma(esp_teste)\n",
    "\n",
    "# Calculate accuracy rates\n",
    "taxa_portugues = resultados_portugues.count(\"portugues\") / len(resultados_portugues)\n",
    "taxa_ingles = resultados_ingles.count(\"ingles\") / len(resultados_ingles)\n",
    "taxa_espanhol = resultados_espanhol.count(\"espanhol\") / len(resultados_espanhol)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Taxa de acerto - Português: {taxa_portugues:.2f}\")\n",
    "print(f\"Taxa de acerto - Inglês: {taxa_ingles:.2f}\")\n",
    "print(f\"Taxa de acerto - Espanhol: {taxa_espanhol:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Perplexity Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the perplexity might be infinite or undefined, which we handled by using Laplace smoothing in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.315093820557337\n",
      "5825.03337622124\n"
     ]
    }
   ],
   "source": [
    "# Example of handling perplexity\n",
    "texto_exemplo = \"good morning\"\n",
    "print(calcular_perplexidade(modelo_ing_Laplace, texto_exemplo))\n",
    "\n",
    "texto_port_teste = port_teste.iloc[0]\n",
    "print(calcular_perplexidade(modelo_ing_Laplace, texto_port_teste))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Perplexity Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a function to calculate perplexity for any given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.315093820557337\n",
      "2008.8011005039791\n",
      "5825.03337622124\n"
     ]
    }
   ],
   "source": [
    "# Final function to calculate perplexity for any text\n",
    "def calcular_perplexidade(modelo, texto):\n",
    "    \"\"\"\n",
    "    Calcula a perplexidade de um texto baseado no modelo fornecido.\n",
    "    - modelo: modelo treinado (MLE ou Laplace)\n",
    "    - texto: string a ser avaliada\n",
    "    \"\"\"\n",
    "    perplexidade = 0\n",
    "    palavras = WhitespaceTokenizer().tokenize(texto)\n",
    "    palavras_fakechar = [list(pad_both_ends(palavra, n=2)) for palavra in palavras]\n",
    "    palavras_bigramns = [list(bigrams(palavra)) for palavra in palavras_fakechar]\n",
    "    \n",
    "    for palavra in palavras_bigramns:\n",
    "        perplexidade += modelo.perplexity(palavra)\n",
    "    \n",
    "    return perplexidade\n",
    "\n",
    "# Testing the function\n",
    "print(calcular_perplexidade(modelo_ing_Laplace, \"good morning\"))\n",
    "print(calcular_perplexidade(modelo_port_Laplace, port_teste.iloc[0]))\n",
    "print(calcular_perplexidade(modelo_ing_Laplace, port_teste.iloc[0]))  # Expected to be higher for incorrect language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project successfully demonstrates the use of n-gram language models for language detection using NLTK. By preprocessing the data and training Laplace-smoothed models, we achieved reasonable accuracy rates in identifying English, Portuguese, and Spanish texts. Future improvements can include expanding the model to support more languages, experimenting with different n-gram sizes, and integrating more sophisticated NLP techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **NLTK Documentation**:\n",
    "   - The official NLTK documentation can be consulted to understand the preprocessing functions, model training, and n-gram generation:\n",
    "     - [NLTK Docs](https://www.nltk.org/)\n",
    "   \n",
    "2. **Bigrams and Language Modeling**:\n",
    "   - The `bigrams` function from NLTK is used to create pairs of words (bigrams) in a text corpus. More details can be found in [NLTK Util Bigram](https://www.nltk.org/api/nltk.html#module-nltk.util).\n",
    "   - The use of `pad_both_ends` helps to add start and end tokens so that bigrams also capture the beginning and ending words of each sentence.\n",
    "   \n",
    "3. **Language Model with NLTK**:\n",
    "   - The NLTK Language Modeling module, such as `MLE` and `Laplace`, is used to estimate probabilities of word sequences. These models are useful for building language detection systems, as described in:\n",
    "     - [NLTK LM](https://www.nltk.org/api/nltk.html#module-nltk.lm)\n",
    "   \n",
    "4. **Calculating Perplexity**:\n",
    "   - Perplexity measures the quality of a language model. The lower the perplexity, the better the model can predict a sequence of words. More information can be found in:\n",
    "     - [Perplexity Explained](https://en.wikipedia.org/wiki/Perplexity)\n",
    "\n",
    "5. **Scikit-Learn Documentation**:\n",
    "   - To understand how to split data into training and test sets, [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) provides a function called `train_test_split`.\n",
    "   \n",
    "6. **Code References**:\n",
    "   - The code was adapted from various sources and best practices within the Natural Language Processing (NLP) and Machine Learning community.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
