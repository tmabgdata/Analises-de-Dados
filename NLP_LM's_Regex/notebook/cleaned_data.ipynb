{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Pipeline for StackOverflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outlines the steps to clean text data from StackOverflow datasets in Spanish, English, and Portuguese. It includes removing HTML tags, handling ``code`` tags, removing excessive line breaks, and sanitizing the data to prepare it for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clean and preprocess the text data from StackOverflow questions in three different languages (Spanish, English, and Portuguese).\n",
    "2. Remove unnecessary HTML tags and `code` tag content.\n",
    "3. Sanitize line breaks, spaces, punctuation, and digits.\n",
    "4. Prepare the cleaned data for further analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps will be taken to preprocess the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Removing HTML Tags\n",
    "\n",
    "- HTML tags can appear in the dataset (e.g., `<a>`, `<b>`, `<code>`) and need to be removed to prevent issues in data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handling Content Inside `<code>` Tags\n",
    "\n",
    "- Code snippets are wrapped inside `<code></code>` tags. We will replace them with the placeholder \"CODE\" to focus on the actual question text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Removing Excessive Line Breaks\n",
    "\n",
    "- Line breaks inside and outside `<code>` tags can cause issues in the dataset. We will handle multiple line breaks by replacing them with a single space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Removing Punctuation and Digits\n",
    "\n",
    "- Any punctuation or digits will be removed to ensure that the data focuses on the textual content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Word Fragmentation\n",
    "\n",
    "- Words like \"co de\" (from split code tags) need to be corrected back to \"code\". We'll fix these kinds of issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Normalization\n",
    "\n",
    "- Convert all text to lowercase and remove extra spaces to standardize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read the CSV files containing StackOverflow questions in Spanish, English, and Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the Spanish, English, and Portuguese CSV files with appropriate encoding and separator\n",
    "path_es = \"../data/stackoverflow_espanhol.csv\"\n",
    "path_en = \"../data/stackoverflow_ingles.csv\"\n",
    "path_pt = \"../data/stackoverflow_portugues.csv\"\n",
    "\n",
    "df_es = pd.read_csv(path_es, encoding=\"ISO-8859-1\", sep=\";\")\n",
    "df_en = pd.read_csv(path_en)\n",
    "df_pt = pd.read_csv(path_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Replacing Content Inside `<code>` Tags\n",
    "We define a function to replace the content inside `<code>` tags with a placeholder \"CODE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to replace the content inside <code> tags with \"CODE\"\n",
    "def replace_code(texts, regex):\n",
    "    if isinstance(texts, str):\n",
    "        return regex.sub(\"CODE\", texts)\n",
    "    else:\n",
    "        return [regex.sub(\"CODE\", text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Removing HTML Tags\n",
    "\n",
    "This function removes all HTML tags from the text using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    regex_html = re.compile(r\"<.*?>\")  # Captures HTML tags\n",
    "    return re.sub(regex_html, \"\", text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fixing Fragmented Words\n",
    "\n",
    "Some words may be fragmented due to code tag processing (e.g., \"co de\" for \"code\"). This function corrects those fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_code_fragment(text):\n",
    "    # Corrigir fragmentações de \"SQL\", \"PHP\", \"code\"\n",
    "    regex_sql_fragment = re.compile(r\"\\b(s\\s*q\\s*l|s[q|l]|[s|q|l]{2,4})\\b\", re.IGNORECASE)  # Captura variações de \"SQL\"\n",
    "    regex_php_fragment = re.compile(r\"\\b(p\\s*h\\s*p|p[h|p]{2})\\b\", re.IGNORECASE)  # Captura variações de \"PHP\"\n",
    "    regex_code_fragment = re.compile(r\"\\b(c\\s*o\\s*d\\s*e|c[o|d|e]{2,4})\\b\", re.IGNORECASE)  # Captura variações de \"code\"\n",
    "    \n",
    "    # Substitui as fragmentações com as palavras completas\n",
    "    text = regex_sql_fragment.sub(\"SQL\", text)\n",
    "    text = regex_php_fragment.sub(\"PHP\", text)\n",
    "    text = regex_code_fragment.sub(\"code\", text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Removing Excessive Line Breaks\n",
    "\n",
    "We need to handle excessive line breaks both inside and outside the `<code>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove excessive line breaks\n",
    "def remove_extra_newlines(text):\n",
    "    return re.sub(r\"[\\n\\s]+\", \" \", text).strip()  # Replaces multiple line breaks with a single space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Removing Punctuation and Digits\n",
    "\n",
    "This function removes punctuation and digits from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuation and digits\n",
    "def remove_punctuation_and_digits(text):\n",
    "    regex_punctuation_digits = re.compile(r\"[^\\w\\s]|[\\d]\")  # Captures punctuation and digits\n",
    "    return re.sub(regex_punctuation_digits, \"\", text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Removing Extra Spaces\n",
    "\n",
    "Extra spaces are often present, and we will ensure that there is only one space between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove extra spaces\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Converting to Lowercase\n",
    "\n",
    "Converting the entire text to lowercase helps normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert text to lowercase\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function applies all the preprocessing steps to the data in the Question column of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, text_column):\n",
    "    # Regex patterns\n",
    "    regex_code = re.compile(r\"<code>.*?</code>\", re.DOTALL)  # Captures <code> tags and their content\n",
    "    regex_html = re.compile(r\"<.*?>\")  # Captures HTML tags\n",
    "    regex_punctuation_digits = re.compile(r\"[^\\w\\s]|[\\d]\")  # Captures punctuation and digits\n",
    "    regex_joint_words = re.compile(r\"([a-zA-Z])([A-Z])\")  # Fixes fragmented words like \"co de\" to \"code\"\n",
    "    \n",
    "    # Apply cleaning functions\n",
    "    df[\"cleaned_code_tag\"] = df[text_column].apply(lambda text: replace_code(text, regex_code))  # Replace content inside <code> tags\n",
    "    df[\"cleaned_code_tag\"] = df[\"cleaned_code_tag\"].apply(remove_html_tags)  # Remove HTML tags\n",
    "    df[\"cleaned_code_tag\"] = df[\"cleaned_code_tag\"].apply(fix_code_fragment)  # Fix fragmented words like \"co de\" to \"code\", \"s q l\" to \"SQL\" and \"p h p\" to \"PHP\"\n",
    "    df[\"cleaned_code_tag\"] = df[\"cleaned_code_tag\"].apply(remove_punctuation_and_digits)  # Remove punctuation and digits\n",
    "    df[\"cleaned_code_tag\"] = df[\"cleaned_code_tag\"].apply(lambda text: re.sub(regex_joint_words, r\"\\1 \\2\", text))  # Fix word fragmentation\n",
    "    df[\"cleaned_code_tag\"] = df[\"cleaned_code_tag\"].apply(convert_to_lowercase)  # Convert to lowercase\n",
    "    df[\"cleaned_code_tag\"] = df[\"cleaned_code_tag\"].apply(remove_extra_spaces)  # Remove extra spaces\n",
    "    df[\"cleaned_code_tag\"] = df[\"cleaned_code_tag\"].apply(remove_extra_newlines)  # Remove excessive line breaks\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Pipeline to Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning pipeline to each dataset\n",
    "df_es_cleaned = clean_text(df_es, \"Questão\")\n",
    "df_en_cleaned = clean_text(df_en, \"Questão\")\n",
    "df_pt_cleaned = clean_text(df_pt, \"Questão\")\n",
    "\n",
    "# Save the cleaned datasets to new CSV files\n",
    "df_es_cleaned.to_csv(\"../cleaned_data/stackoverflow_spanish_clean.csv\", index=False)\n",
    "df_en_cleaned.to_csv(\"../cleaned_data/stackoverflow_english_clean.csv\", index=False)\n",
    "df_pt_cleaned.to_csv(\"../cleaned_data/stackoverflow_portuguese_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have an array that is initialized like code i would like to convert this array into an object of the array list class code\n"
     ]
    }
   ],
   "source": [
    "print(df_en_cleaned.cleaned_code_tag[95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "já li alguns comentários na web a respeito de utilizar ou não o code no final das linhas quando se escreve java script alguns dizem que sim outros dizem não ter necessidade mas nenhum sabe explicar bem os motivos das divergências exemplo code o interessante é que mesmo esquecendo o code no meu código as vezes ele continua rodando sem problemas e sem disparar erros então o correto é usar ou não o famoso ponto e vírgula\n"
     ]
    }
   ],
   "source": [
    "print(df_pt_cleaned.cleaned_code_tag[94])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "como parte de un trabajo de compiladores debo programar un editor de texto que reciba como entrada el lenguaje visual basic y lo transforme a otro lenguaje a mi eleccion actualmente estoy utilizando visual basic para programar lo anterior lo primero que hice fue recibir la cadena de entrada y separarla en tokens clasificandolos en palabras reservadas variables simbolos de agrupacion y operadores code metodo para evaluar tokens code automata para evaluar si token es numero code los tokens despues de ser evaluados por automatas los almaceno en list views que despues muestro en una ventana code para este traductor no debo hacer validaciones de signos de agrupación que verifiquen si faltan paréntesis o llaves solamente transformar los tokens obtenidos a otro lenguaje el lenguaje final puede ser cualquiera asimismo no es todo el lenguaje el que debo convertir solo la estructura de un for while e if por ejemplo si tengo code debo convertirlo a code en este caso los tokens que tengo son linea code linea code lo he intentado de diversas formas pero no logro que me funcione la traducción de los tokens lo que necesito ayuda es si me pueden decir como hacer una plantilla que reciba los tokens y los cambie al nuevo lenguaje por favor si alguien puede ayudarme muy agradecido\n"
     ]
    }
   ],
   "source": [
    "print(df_es_cleaned.cleaned_code_tag[99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project successfully cleaned the StackOverflow datasets, removing unnecessary fragments and excess text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
