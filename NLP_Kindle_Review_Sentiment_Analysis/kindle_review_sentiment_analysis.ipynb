{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kindle Review Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview  \n",
    "### Context  \n",
    "This dataset is a small subset of Amazon Kindle Store book reviews.  \n",
    "\n",
    "### Content  \n",
    "The dataset includes 982,619 entries of product reviews from May 1996 to July 2014, where each reviewer and product has at least 5 reviews.  \n",
    "\n",
    "#### Columns:  \n",
    "- **asin**: Unique product ID (e.g., `B000FA64PK`).  \n",
    "- **helpful**: Helpfulness rating of the review (e.g., `2/3`).  \n",
    "- **overall**: Product rating.  \n",
    "- **reviewText**: Full text of the review.  \n",
    "- **reviewTime**: Review timestamp (raw format).  \n",
    "- **reviewerID**: Unique reviewer ID (e.g., `A3SPTOKDG7WBLN`).  \n",
    "- **reviewerName**: Name of the reviewer.  \n",
    "- **summary**: Summary or title of the review.  \n",
    "- **unixReviewTime**: Unix timestamp of the review.  \n",
    "\n",
    "### Acknowledgements  \n",
    "This dataset was sourced from the Amazon product data repository by Julian McAuley (UCSD). Full dataset details are available [here](http://jmcauley.ucsd.edu/data/amazon/).  \n",
    "\n",
    "### Potential Analyses  \n",
    "- **Sentiment Analysis**: Extract and analyze sentiments from review texts.  \n",
    "- **Helpfulness Analysis**: Understand factors influencing review helpfulness.  \n",
    "- **Outlier Detection**: Identify fake or unusual reviews.  \n",
    "- **Product Insights**: Find top-rated products or analyze product similarities based on reviews.  \n",
    "- **Other Explorations**: Discover unique patterns or insights from the data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practises\n",
    "\n",
    "1. Preprocessing And Cleaning\n",
    "2. Train Test Split\n",
    "3. BOW, TFIDF, Word2vec\n",
    "4. Train ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the dataset\n",
    "file_path = r\"D:\\Repositories\\Data-Science\\NLP_Kindle_Review_Sentiment_Analysis\\data\\all_kindle_review.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first five rows\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Relevant Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3\n",
       "1  Great short read.  I didn't want to put it dow...       5\n",
       "2  I'll start by saying this is the first of four...       3\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4  I did not expect this type of book to be in li...       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting relevant columns: 'reviewText' and 'rating'\n",
    "df = data[['reviewText', 'rating']]\n",
    "\n",
    "# Display the first five rows of the selected DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Shape of the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the DataFrame (rows, columns)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Unique Values in the Rating Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values in the 'rating' column\n",
    "df['rating'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting the Frequency of Each Rating Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the frequency of each value in the 'rating' column\n",
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing And Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Ratings to Binary Labels (Positive: 1, Negative: 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\34327109.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rating'] = df['rating'].apply(lambda x: 0 if x < 3 else 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert ratings to binary labels: Positive (1) if rating >= 3, otherwise Negative (0)\n",
    "df['rating'] = df['rating'].apply(lambda x: 0 if x < 3 else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of Binary Rating Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the frequency of binary labels in the 'rating' column\n",
    "df['rating'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting All Review Text to Lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\2955130842.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may be short, but he's nothing to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read.  i didn't want to put it dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'll start by saying this is the first of four...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie is angela lansbury who carries pocketboo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i did not expect this type of book to be in li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may be short, but he's nothing to ...       1\n",
       "1  great short read.  i didn't want to put it dow...       1\n",
       "2  i'll start by saying this is the first of four...       1\n",
       "3  aggie is angela lansbury who carries pocketboo...       1\n",
       "4  i did not expect this type of book to be in li...       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all text in the 'reviewText' column to lowercase\n",
    "df['reviewText'] = df['reviewText'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Downloading Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import BeautifulSoup for parsing HTML content\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Review Text\n",
    "- Removing special characters\n",
    "- Removing stopwords\n",
    "- Removing URLs\n",
    "- Removing HTML tags\n",
    "- Removing extra spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\3326109532.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s-]+', '', x))\n",
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\3326109532.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\3326109532.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://[\\w\\.-]+(?:/[\\w\\./-]*)?', '', str(x)))\n",
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\3326109532.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\3326109532.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x.split()))\n"
     ]
    }
   ],
   "source": [
    "# Removing special characters\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s-]+', '', x))\n",
    "\n",
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "# Removing URLs\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://[\\w\\.-]+(?:/[\\w\\./-]*)?', '', str(x)))\n",
    "\n",
    "# Removing HTML tags\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "\n",
    "# Removing additional spaces\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x.split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing: Lemmatization and WordNet Lemmatizer\n",
    "- Initializing WordNet Lemmatizer\n",
    "- Defining Lemmatization Function\n",
    "- Applying Lemmatization on Review Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmada\\AppData\\Local\\Temp\\ipykernel_4808\\1843008944.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lambda x: lemmatize_words(x))\n"
     ]
    }
   ],
   "source": [
    "# Import WordNetLemmatizer from NLTK\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to lemmatize words in the text\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "# Apply the lemmatization function to the 'reviewText' column\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: lemmatize_words(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "- Splitting the dataset into training and testing sets\n",
    "- 80% for training, 20% for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviewText'], df['rating'], test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW) Transformation\n",
    "- Converting text data into numerical format using CountVectorizer\n",
    "- Training set and test set transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "bow = CountVectorizer()\n",
    "\n",
    "# Transform the training and testing data using CountVectorizer (Bag of Words)\n",
    "X_train_bow = bow.fit_transform(X_train).toarray()\n",
    "X_test_bow = bow.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Transformation\n",
    "- Converting text data into numerical format using TfidfVectorizer\n",
    "- Training set and test set transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Transform the training and testing data using TfidfVectorizer (TF-IDF)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Bag of Words Transformation (Training Set)\n",
    "- Displaying the numerical representation of the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the Bag of Words transformation of the training data\n",
    "X_train_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>002</th>\n",
       "      <th>007</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>05142012</th>\n",
       "      <th>06</th>\n",
       "      <th>067day12262010</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zorns</th>\n",
       "      <th>zsadist</th>\n",
       "      <th>zsadists</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zwhy</th>\n",
       "      <th>zyra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  002  007  04  05  05142012  06  067day12262010  07  ...  \\\n",
       "0   0    0    0    0   0   0         0   0               0   0  ...   \n",
       "1   0    0    0    0   0   0         0   0               0   0  ...   \n",
       "2   0    0    0    0   0   0         0   0               0   0  ...   \n",
       "3   0    0    0    0   0   0         0   0               0   0  ...   \n",
       "4   0    0    0    0   0   0         0   0               0   0  ...   \n",
       "\n",
       "   zoological  zoom  zoomed  zorn  zorns  zsadist  zsadists  zulu  zwhy  zyra  \n",
       "0           0     0       0     0      0        0         0     0     0     0  \n",
       "1           0     0       0     0      0        0         0     0     0     0  \n",
       "2           0     0       0     0      0        0         0     0     0     0  \n",
       "3           0     0       0     0      0        0         0     0     0     0  \n",
       "4           0     0       0     0      0        0         0     0     0     0  \n",
       "\n",
       "[5 rows x 35766 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature names (words) from the Bag of Words model\n",
    "feature_names = bow.get_feature_names_out()\n",
    "\n",
    "# Convert the matrix to a DataFrame with feature names as columns\n",
    "import pandas as pd\n",
    "X_train_bow_df = pd.DataFrame(X_train_bow, columns=feature_names)\n",
    "\n",
    "# Display the first few rows of the Bag of Words DataFrame\n",
    "X_train_bow_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Naive Bayes Classifier\n",
    "- Training Gaussian Naive Bayes model using Bag of Words (BoW) representation\n",
    "- Training Gaussian Naive Bayes model using TF-IDF representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GaussianNB from scikit-learn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Train Naive Bayes model on Bag of Words features (X_train_bow)\n",
    "nb_model_bow = GaussianNB().fit(X_train_bow, y_train)\n",
    "\n",
    "# Train Naive Bayes model on TF-IDF features (X_train_tfidf)\n",
    "nb_model_tfidf = GaussianNB().fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation - Naive Bayes (BoW)\n",
    "- Evaluating the Naive Bayes model performance using:\n",
    "  - Confusion Matrix\n",
    "  - Accuracy Score\n",
    "  - Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (BoW):\n",
      " [[504 309]\n",
      " [719 868]]\n",
      "\n",
      "Accuracy Score (BoW): 0.5716666666666667\n",
      "\n",
      "Classification Report (BoW):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.62      0.50       813\n",
      "           1       0.74      0.55      0.63      1587\n",
      "\n",
      "    accuracy                           0.57      2400\n",
      "   macro avg       0.57      0.58      0.56      2400\n",
      "weighted avg       0.63      0.57      0.58      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure the prediction is done first\n",
    "y_pred_bow = nb_model_bow.predict(X_test_bow)  # Making predictions with Naive Bayes model\n",
    "\n",
    "# Importing evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_bow = confusion_matrix(y_test, y_pred_bow)\n",
    "print(\"Confusion Matrix (BoW):\\n\", conf_matrix_bow)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy_bow = accuracy_score(y_test, y_pred_bow)\n",
    "print(\"\\nAccuracy Score (BoW):\", accuracy_bow)\n",
    "\n",
    "# Classification Report\n",
    "class_report_bow = classification_report(y_test, y_pred_bow)\n",
    "print(\"\\nClassification Report (BoW):\\n\", class_report_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Accuracy:  0.5716666666666667\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score\n",
    "accuracy_bow = accuracy_score(y_test, y_pred_bow)\n",
    "print(\"BoW Accuracy: \", accuracy_bow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation - Naive Bayes (TF-IDF)\n",
    "- Evaluating the Naive Bayes model performance using the Confusion Matrix.\n",
    "- The confusion matrix will help identify the number of correct and incorrect classifications made by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (TF-IDF):\n",
      " [[494 319]\n",
      " [702 885]]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions with Naive Bayes model (TF-IDF)\n",
    "y_pred_tfidf = nb_model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Importing necessary evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
    "print(\"Confusion Matrix (TF-IDF):\\n\", conf_matrix_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF accuracy:  0.5745833333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDF accuracy: \",accuracy_score(y_test,y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion - Sentiment Analysis Evaluation\n",
    "\n",
    "This project aimed to evaluate sentiment analysis using **Naive Bayes** models, leveraging different text vectorization techniques: **Bag of Words (BoW)** and **TF-IDF**. Both methods provide insights into the effectiveness of these models in classifying sentiment (positive vs. negative reviews). Below are the findings:\n",
    "\n",
    "### **Bag of Words (BoW)**:\n",
    "- **Accuracy Score**: 57.17%\n",
    "- **Confusion Matrix**:\n",
    "  - True Negatives (Negative Reviews): 504\n",
    "  - False Positives (Incorrectly classified as Positive): 309\n",
    "  - False Negatives (Incorrectly classified as Negative): 719\n",
    "  - True Positives (Correctly classified as Positive): 868\n",
    "- **Classification Report**:\n",
    "  - **Precision** for class 1 (positive sentiment) is 0.74, indicating the model is good at identifying positive sentiment when it predicts it, but with some room for improvement in recall (0.55).\n",
    "  - **Recall** for negative reviews (class 0) is 0.62, suggesting the model is better at identifying negative reviews, though still leaving some false negatives.\n",
    "\n",
    "### **TF-IDF**:\n",
    "- **Accuracy Score**: 57.46%\n",
    "- **Confusion Matrix**:\n",
    "  - True Negatives: 494\n",
    "  - False Positives: 319\n",
    "  - False Negatives: 702\n",
    "  - True Positives: 885\n",
    "- **Classification Report**:\n",
    "  - The TF-IDF model showed a slightly higher accuracy than BoW (57.46%), with an improved performance in identifying positive reviews (class 1), though the recall is still lower compared to its precision (0.55).\n",
    "  - The model performed similarly in terms of recall for class 0 (negative sentiment), where the recall was 0.55.\n",
    "\n",
    "### **Insights**:\n",
    "- Both models performed relatively well, achieving accuracy in the range of 57%, but they show a **bias towards identifying negative reviews** (class 0), possibly because of the higher frequency of negative reviews in the dataset.\n",
    "- The **TF-IDF model slightly outperformed BoW** in terms of overall accuracy, which indicates that capturing word importance (via TF-IDF) is slightly more effective for this sentiment analysis task compared to the simple frequency count of BoW.\n",
    "\n",
    "### **Next Steps and Recommendations**:\n",
    "1. **Advanced Models**: Explore more sophisticated models, such as **Logistic Regression**, **Support Vector Machines (SVM)**, or **Gradient Boosting Machines (GBM)**, which may provide better classification performance.\n",
    "2. **Deep Learning Models**: Consider leveraging **LSTM (Long Short-Term Memory)** or **BERT (Bidirectional Encoder Representations from Transformers)** for deeper semantic understanding and improved sentiment classification.\n",
    "3. **Fine-tuning Pretrained Models**: Utilize pre-trained transformer models, such as BERT or RoBERTa, which have shown state-of-the-art results in sentiment analysis tasks and can be fine-tuned for better accuracy.\n",
    "4. **Data Augmentation**: Use techniques such as **back-translation** or **data synthesis** to balance the dataset and improve the model's ability to generalize across both positive and negative sentiments.\n",
    "\n",
    "By incorporating these strategies, the overall performance of the sentiment analysis could be significantly improved, resulting in more accurate and reliable predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
